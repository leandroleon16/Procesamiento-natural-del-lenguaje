{"cells":[{"cell_type":"markdown","metadata":{"id":"pfa39F4lsLf3"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## LSTM Bot QA"]},{"cell_type":"markdown","metadata":{"id":"ZqO0PRcFsPTe"},"source":["### Datos\n","El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n","[LINK](http://convai.io/data/)"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"bDFC0I3j9oFD","executionInfo":{"status":"ok","timestamp":1701222868156,"user_tz":180,"elapsed":10696,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"outputs":[],"source":["!pip install --upgrade --no-cache-dir gdown --quiet"]},{"cell_type":"code","source":["!pip install --upgrade tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCUf1Nq2qZ9H","executionInfo":{"status":"ok","timestamp":1701222887708,"user_tz":180,"elapsed":15698,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"796a9eba-406a-4408-9270-3a9334dd6669"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","execution_count":63,"metadata":{"id":"cq3YXak9sGHd","executionInfo":{"status":"ok","timestamp":1701222932861,"user_tz":180,"elapsed":832,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"outputs":[],"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from keras.preprocessing.text import one_hot\n","from tensorflow.keras.utils import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM, SimpleRNN\n","from keras.models import Model\n","from tensorflow.keras.layers import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["import os\n","import platform\n","\n","if os.access('torch_helpers.py', os.F_OK) is False:\n","    if platform.system() == 'Windows':\n","        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n","    else:\n","        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"],"metadata":{"id":"_nDiaMQ55q_E","executionInfo":{"status":"ok","timestamp":1701222974162,"user_tz":180,"elapsed":611,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","execution_count":65,"metadata":{"id":"RHNkUaPp6aYq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701222976602,"user_tz":180,"elapsed":5,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"9c5b223c-07ad-4ece-e227-ae1cb48d040f"},"outputs":[{"output_type":"stream","name":"stdout","text":["El dataset ya se encuentra descargado\n"]}],"source":["# Descargar la carpeta de dataset\n","import os\n","import gdown\n","if os.access('data_volunteers.json', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n","    output = 'data_volunteers.json'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"WZy1-wgG-Rp7","executionInfo":{"status":"ok","timestamp":1701222980796,"user_tz":180,"elapsed":4,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"outputs":[],"source":["# dataset_file\n","import json\n","\n","text_file = \"data_volunteers.json\"\n","with open(text_file) as f:\n","    data = json.load(f) # la variable data será un diccionario\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ue5qd54S-eew","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701222230434,"user_tz":180,"elapsed":4,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"a34c051f-a61a-4f55-f200-739193f545cf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"]},"metadata":{},"execution_count":36}],"source":["# Observar los campos disponibles en cada linea del dataset\n","data[0].keys()"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"jHBRAXPl-3dz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701222985944,"user_tz":180,"elapsed":514,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"ee1cd274-1370-4b50-95a0-ee8146912aec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cantidad de rows utilizadas: 6033\n"]}],"source":["chat_in = []\n","chat_out = []\n","\n","input_sentences = []\n","output_sentences = []\n","output_sentences_inputs = []\n","max_len = 30\n","\n","def clean_text(txt):\n","    txt = txt.lower()\n","    txt.replace(\"\\'d\", \" had\")\n","    txt.replace(\"\\'s\", \" is\")\n","    txt.replace(\"\\'m\", \" am\")\n","    txt.replace(\"don't\", \"do not\")\n","    txt = re.sub(r'\\W+', ' ', txt)\n","\n","    return txt\n","\n","for line in data:\n","    for i in range(len(line['dialog'])-1):\n","        # vamos separando el texto en \"preguntas\" (chat_in)\n","        # y \"respuestas\" (chat_out)\n","        chat_in = clean_text(line['dialog'][i]['text'])\n","        chat_out = clean_text(line['dialog'][i+1]['text'])\n","\n","        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n","            continue\n","\n","        input_sentence, output = chat_in, chat_out\n","\n","        # output sentence (decoder_output) tiene <eos>\n","        output_sentence = output + ' <eos>'\n","        # output sentence input (decoder_input) tiene <sos>\n","        output_sentence_input = '<sos> ' + output\n","\n","        input_sentences.append(input_sentence)\n","        output_sentences.append(output_sentence)\n","        output_sentences_inputs.append(output_sentence_input)\n","\n","print(\"Cantidad de rows utilizadas:\", len(input_sentences))"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"07L1qj8pC_l6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701222990993,"user_tz":180,"elapsed":652,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"b8c8fd75-fe67-41f8-f4e1-a102a4262d82"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"]},"metadata":{},"execution_count":68}],"source":["input_sentences[1], output_sentences[1], output_sentences_inputs[1]"]},{"cell_type":"markdown","metadata":{"id":"8P-ynUNP5xp6"},"source":["### 2 - Preprocesamiento\n","Realizar el preprocesamiento necesario para obtener:\n","- word2idx_inputs, max_input_len\n","- word2idx_outputs, max_out_len, num_words_output\n","- encoder_input_sequences, decoder_output_sequences, decoder_targets"]},{"cell_type":"code","source":["# Definir el tamaño máximo del vocabulario\n","MAX_VOCAB_SIZE = 8000\n","MAX_LENGTH = 10\n","N_UNITS = 128\n","EPOCHS = 40\n","LSTM_DROPOUT = 0.2"],"metadata":{"id":"s6x6eT5r5B4E","executionInfo":{"status":"ok","timestamp":1701222996608,"user_tz":180,"elapsed":450,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["# Tokenizar las palabras con el Tokenizer de Keras\n","# Definir una máxima cantidad de palabras a utilizar:\n","# - num_words --> the maximum number of words to keep, based on word frequency.\n","# - Only the most common num_words-1 words will be kept.\n","from torch_helpers import Tokenizer\n","input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n","input_tokenizer.fit_on_texts(input_sentences)\n","input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n","\n","word2idx_inputs = input_tokenizer.word_index\n","print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n","\n","max_input_len = max(len(sen) for sen in input_integer_seq)\n","print(\"Sentencia de entrada más larga:\", max_input_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwLLzWjy5aic","executionInfo":{"status":"ok","timestamp":1701223001709,"user_tz":180,"elapsed":919,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"34cae4ae-23ec-4958-d30f-6ae6e7050bef"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Palabras en el vocabulario: 1799\n","Sentencia de entrada más larga: 9\n"]}]},{"cell_type":"code","source":["# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n","# sacamos los \"<>\" para que no afectar nuestros tokens\n","output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\]^_`{|}~\\t\\n')\n","output_tokenizer.fit_on_texts([\"\", \"\"] + output_sentences)\n","output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n","output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n","\n","word2idx_outputs = output_tokenizer.word_index\n","print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n","\n","num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer\n","print(\"Palabras de salida:\", num_words_output)\n","\n","max_out_len = max(len(sen) for sen in output_integer_seq)\n","print(\"Sentencia de salida más larga:\", max_out_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgzwGSpm54X8","executionInfo":{"status":"ok","timestamp":1701223006748,"user_tz":180,"elapsed":764,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"c46dd95f-af82-44a1-f6d0-adf177ffd597"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Palabras en el vocabulario: 1805\n","Palabras de salida: 1806\n","Sentencia de salida más larga: 10\n"]}]},{"cell_type":"code","source":["# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n","# a la mitad:\n","max_input_len = 16\n","max_out_len = 18"],"metadata":{"id":"F-xEFzZQ6IXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.utils import to_categorical"],"metadata":{"id":"145W6XGyr5FP","executionInfo":{"status":"ok","timestamp":1701223017684,"user_tz":180,"elapsed":573,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n","print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n","\n","decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n","print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n","\n","decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n","print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)\n","\n","decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n","print(\"decoder_targets shape:\", decoder_targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pdsdejjr6zs","executionInfo":{"status":"ok","timestamp":1701223023377,"user_tz":180,"elapsed":549,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"c15da42e-7041-4576-bbd7-d76805b6b9c8"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["encoder_input_sequences shape: (6033, 9)\n","decoder_input_sequences shape: (6033, 10)\n","decoder_output_sequences shape: (6033, 10)\n","decoder_targets shape: (6033, 10, 1806)\n"]}]},{"cell_type":"markdown","metadata":{"id":"_CJIsLBbj6rg"},"source":["### 3 - Preparar los embeddings\n","Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"]},{"cell_type":"code","source":["if os.access('fasttext.pkl', os.F_OK) is False:\n","    url = 'https://drive.google.com/u/0/uc?id=1Qi1r-u5lsEsNqRSxLrpNOqQ3B_ufltCa&export=download&confirm=t'\n","    output = 'fasttext.pkl'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"Los embeddings de fasttext ya están descargados.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOt9pW7JsUGg","executionInfo":{"status":"ok","timestamp":1701223031125,"user_tz":180,"elapsed":6,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"168855f5-7145-4e04-cd0a-5e5527c4e72d"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Los embeddings de fasttext ya están descargados.\n"]}]},{"cell_type":"code","source":["import logging\n","import os\n","from pathlib import Path\n","from io import StringIO\n","import pickle\n","\n","class WordsEmbeddings(object):\n","    logger = logging.getLogger(__name__)\n","\n","    def __init__(self):\n","        # load the embeddings\n","        words_embedding_pkl = Path(self.PKL_PATH)\n","        if not words_embedding_pkl.is_file():\n","            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n","            assert words_embedding_txt.is_file(), 'Words embedding not available'\n","            embeddings = self.convert_model_to_pickle()\n","        else:\n","            embeddings = self.load_model_from_pickle()\n","        self.embeddings = embeddings\n","        # build the vocabulary hashmap\n","        index = np.arange(self.embeddings.shape[0])\n","        # Dicctionarios para traducir de embedding a IDX de la palabra\n","        self.word2idx = dict(zip(self.embeddings['word'], index))\n","        self.idx2word = dict(zip(index, self.embeddings['word']))\n","\n","    def get_words_embeddings(self, words):\n","        words_idxs = self.words2idxs(words)\n","        return self.embeddings[words_idxs]['embedding']\n","\n","    def words2idxs(self, words):\n","        return np.array([self.word2idx.get(word, -1) for word in words])\n","\n","    def idxs2words(self, idxs):\n","        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n","\n","    def load_model_from_pickle(self):\n","        self.logger.debug(\n","            'loading words embeddings from pickle {}'.format(\n","                self.PKL_PATH\n","            )\n","        )\n","        max_bytes = 2**28 - 1 # 256MB\n","        bytes_in = bytearray(0)\n","        input_size = os.path.getsize(self.PKL_PATH)\n","        with open(self.PKL_PATH, 'rb') as f_in:\n","            for _ in range(0, input_size, max_bytes):\n","                bytes_in += f_in.read(max_bytes)\n","        embeddings = pickle.loads(bytes_in)\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","    def convert_model_to_pickle(self):\n","        # create a numpy strctured array:\n","        # word     embedding\n","        # U50      np.float32[]\n","        # word_1   a, b, c\n","        # word_2   d, e, f\n","        # ...\n","        # word_n   g, h, i\n","        self.logger.debug(\n","            'converting and loading words embeddings from text file {}'.format(\n","                self.WORD_TO_VEC_MODEL_TXT_PATH\n","            )\n","        )\n","        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n","                     ('embedding', np.float32, (self.N_FEATURES,))]\n","        structure = np.dtype(structure)\n","        # load numpy array from disk using a generator\n","        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n","            embeddings_gen = (\n","                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n","                if len(line.split()[1:]) == self.N_FEATURES\n","            )\n","            embeddings = np.fromiter(embeddings_gen, structure)\n","        # add a null embedding\n","        null_embedding = np.array(\n","            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n","            dtype=structure\n","        )\n","        embeddings = np.concatenate([embeddings, null_embedding])\n","        # dump numpy array to disk using pickle\n","        max_bytes = 2**28 - 1 # # 256MB\n","        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n","        with open(self.PKL_PATH, 'wb') as f_out:\n","            for idx in range(0, len(bytes_out), max_bytes):\n","                f_out.write(bytes_out[idx:idx+max_bytes])\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","class FasttextEmbeddings(WordsEmbeddings):\n","    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n","    PKL_PATH = 'fasttext.pkl'\n","    N_FEATURES = 300\n","    WORD_MAX_SIZE = 60"],"metadata":{"id":"DtGs9bbI7uTE","executionInfo":{"status":"ok","timestamp":1701223037685,"user_tz":180,"elapsed":3,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["model_embeddings = FasttextEmbeddings()\n","\n","print('preparing embedding matrix...')\n","embed_dim = model_embeddings.N_FEATURES\n","words_not_found = []\n","\n","# word_index provieen del tokenizer\n","\n","nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n","embedding_matrix = np.zeros((nb_words, embed_dim))\n","for word, i in word2idx_inputs.items():\n","    if i >= nb_words:\n","        continue\n","    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n","    if (embedding_vector is not None) and len(embedding_vector) > 0:\n","\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","        # words not found in embedding index will be all-zeros.\n","        words_not_found.append(word)\n","\n","print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))\n","\n"],"metadata":{"id":"dK1YeXMh8D3l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701223071604,"user_tz":180,"elapsed":28488,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"57df6d00-615d-48dd-9123-b75b96910332"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["preparing embedding matrix...\n"]}]},{"cell_type":"code","source":["# Dimensión de los embeddings de la secuencia en ingles\n","embedding_matrix.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9m5uftY8NpM","executionInfo":{"status":"ok","timestamp":1701223116894,"user_tz":180,"elapsed":643,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"420cd9ce-eb67-46db-f5ed-69b6d9679712"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1799, 300)"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":[],"metadata":{"id":"3ARE5m0q1XVg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3vKbhjtIwPgM"},"source":["### 4 - Entrenar el modelo\n","Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."]},{"cell_type":"code","source":["# define training encoder\n","\n","encoder_inputs = Input(shape=(max_input_len))\n","\n","encoder_embedding_layer = Embedding(\n","    input_dim=nb_words,\n","    output_dim=embed_dim,\n","    input_length=max_input_len,\n","    weights=[embedding_matrix],\n","    trainable=False)\n","\n","encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n","\n","encoder = LSTM(N_UNITS,\n","               return_state=True,\n","               dropout=LSTM_DROPOUT,\n","               )\n","\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n","encoder_states = [state_h, state_c]\n","\n","# define training decoder\n","decoder_inputs = Input(shape=(max_out_len))\n","decoder_embedding_layer = Embedding(\n","    input_dim=num_words_output,\n","    output_dim=N_UNITS,\n","    input_length=max_out_len)\n","decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n","\n","decoder_lstm = LSTM(N_UNITS,\n","                    return_sequences=True,\n","                    return_state=True,\n","                    dropout=LSTM_DROPOUT,\n","                    )\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n","\n","# Dense\n","decoder_dense = Dense(num_words_output, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmTMsH6jp2fO","executionInfo":{"status":"ok","timestamp":1701223534004,"user_tz":180,"elapsed":809,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"14d5cf0d-ba92-47bf-f047-1298f66f2d61"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_14\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_25 (InputLayer)       [(None, 9)]                  0         []                            \n","                                                                                                  \n"," input_26 (InputLayer)       [(None, 10)]                 0         []                            \n","                                                                                                  \n"," embedding_12 (Embedding)    (None, 9, 300)               539700    ['input_25[0][0]']            \n","                                                                                                  \n"," embedding_13 (Embedding)    (None, 10, 128)              231168    ['input_26[0][0]']            \n","                                                                                                  \n"," lstm_12 (LSTM)              [(None, 128),                219648    ['embedding_12[0][0]']        \n","                              (None, 128),                                                        \n","                              (None, 128)]                                                        \n","                                                                                                  \n"," lstm_13 (LSTM)              [(None, 10, 128),            131584    ['embedding_13[0][0]',        \n","                              (None, 128),                           'lstm_12[0][1]',             \n","                              (None, 128)]                           'lstm_12[0][2]']             \n","                                                                                                  \n"," dense_6 (Dense)             (None, 10, 1806)             232974    ['lstm_13[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 1355074 (5.17 MB)\n","Trainable params: 815374 (3.11 MB)\n","Non-trainable params: 539700 (2.06 MB)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["encoder_model = Model(encoder_inputs, encoder_states)"],"metadata":{"id":"TqHULq6AtV64","executionInfo":{"status":"ok","timestamp":1701223136212,"user_tz":180,"elapsed":4,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["decoder_state_input_h = Input(shape=(N_UNITS,))\n","decoder_state_input_c = Input(shape=(N_UNITS,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_inputs_single = Input(shape=(1,))\n","decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"],"metadata":{"id":"3-RZOni1ta3g","executionInfo":{"status":"ok","timestamp":1701223139487,"user_tz":180,"elapsed":465,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["hist = model.fit( [encoder_input_sequences, decoder_input_sequences],decoder_targets,epochs=EPOCHS,validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rMi58o2NtfSP","executionInfo":{"status":"error","timestamp":1701223166420,"user_tz":180,"elapsed":23573,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"6cee1e82-9c2b-40fb-ef57-4409c49b3ebe"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","151/151 [==============================] - ETA: 0s - loss: 3.1129 - accuracy: 0.4988"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-5ed91e11058e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencoder_input_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_sequences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node model_10/embedding_8/embedding_lookup defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-81-5ed91e11058e>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1856, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2296, in evaluate\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 4108, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py\", line 272, in call\n\nindices[14,8] = 1799 is not in [0, 1799)\n\t [[{{node model_10/embedding_8/embedding_lookup}}]] [Op:__inference_test_function_27301]"]}]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","epoch_count = range(1, len(hist.history['accuracy']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"1Uf4NJJouBC3","executionInfo":{"status":"error","timestamp":1701219008018,"user_tz":180,"elapsed":19,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"ea889adf-985d-44a3-a73d-ed3f84bfc04d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-8c81f2e14899>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"Zbwn0ekDy_s2"},"source":["### 5 - Inferencia\n","Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."]},{"cell_type":"code","source":["# Armar lo conversores de indice a palabra:\n","idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n","idx2word_target = {v:k for k, v in word2idx_outputs.items()}"],"metadata":{"id":"OMetSf4JuGbY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def answer_prompt(input_seq):\n","    # Obtener los estados internos del modelo del codificador\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Inicializar la secuencia de destino con el token de inicio <sos>\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = word2idx_outputs['<sos>']\n","\n","    # Obtener el índice del token de final de oración\n","    eos = word2idx_outputs['<eos>']\n","\n","    # Inicializar una lista para almacenar la traducción de salida\n","    output_sentence = []\n","\n","    # Generar la secuencia de salida\n","    for _ in range(max_out_len):\n","        # Predecir los tokens de salida y los estados internos del modelo del decodificador\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # Encontrar el índice del token con la probabilidad más alta\n","        idx = np.argmax(output_tokens[0, 0, :])\n","\n","        # Comprobar si el token predicho es un token de final de oración\n","        if eos == idx:\n","            break\n","\n","        word = ''\n","        if idx > 0:\n","            # Obtener la palabra correspondiente al índice predicho\n","            word = idx2word_target[idx]\n","            # Agregar la palabra a la traducción de salida\n","            output_sentence.append(word)\n","\n","        # Actualizar los estados internos para la siguiente iteración\n","        states_value = [h, c]\n","        # Establecer el token predicho como entrada para la siguiente iteración\n","        target_seq[0, 0] = idx\n","\n","    # Devolver la traducción de salida como una cadena\n","    return ' '.join(output_sentence)\n"],"metadata":{"id":"CLuYhqaFuNZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paso 1: Tokenizar la entrada de prueba\n","input_test = \"Do you read?\"\n","input_seq = input_tokenizer.texts_to_sequences([input_test])\n","encoder_input_seq = pad_sequences(input_seq, maxlen=max_input_len)\n","\n","# Paso 2: Realizar la inferencia utilizando la función `answer_prompt`\n","translation = answer_prompt(encoder_input_seq)\n","\n","# Paso 3: Imprimir la traducción\n","print('Input:', input_test)\n","print(\"Representación en vector de tokens de IDs:\", encoder_input_seq)\n","print('Response:', translation)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAPhUE6tvsi3","executionInfo":{"status":"ok","timestamp":1698018207945,"user_tz":180,"elapsed":611,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"7bc926ae-5b72-479f-ee29-8c84db9c0577"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 337ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Input: Do you read?\n","Representación en vector de tokens de IDs: [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  2 23]]\n","Response: i like to read\n"]}]},{"cell_type":"code","source":["input_test = 'Do you have any pet?'\n","print('Input:', input_test)\n","integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n","print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n","encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n","print(\"Padding del vector:\", encoder_sequence_test)\n","\n","print('Input:', input_test)\n","translation = answer_prompt(encoder_sequence_test)\n","print('Response:', translation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdFUiLe1xcP9","executionInfo":{"status":"ok","timestamp":1698018233228,"user_tz":180,"elapsed":1113,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"e9856db7-71cc-4d41-afd5-d608316a87e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: Do you have any pet?\n","Representacion en vector de tokens de ids [3, 2, 16, 31, 252]\n","Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   3   2  16  31 252]]\n","Input: Do you have any pet?\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Response: yes i do not\n"]}]},{"cell_type":"code","source":["input_test = 'Where are you from?'\n","print('Input:', input_test)\n","integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n","print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n","encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n","print(\"Padding del vector:\", encoder_sequence_test)\n","\n","print('Input:', input_test)\n","translation = answer_prompt(encoder_sequence_test)\n","print('Response:', translation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlKZIl2fxmh2","executionInfo":{"status":"ok","timestamp":1698018262224,"user_tz":180,"elapsed":1097,"user":{"displayName":"Leandro Leon (ontvonline.net)","userId":"03611305714687899577"}},"outputId":"3b347651-8f16-4eea-e0c1-72f09d552d63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: Where are you from?\n","Representacion en vector de tokens de ids [52, 7, 2, 39]\n","Padding del vector: [[ 0  0  0  0  0  0  0  0  0  0  0  0 52  7  2 39]]\n","Input: Where are you from?\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Response: i am not sure what you mean\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}